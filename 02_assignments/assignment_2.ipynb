{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0bcac6-5086-4f4e-928a-570a9ff7ae58",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce0350-2a17-4e93-8d4c-0b8748fdfc32",
   "metadata": {},
   "source": [
    "As before, if a question can be answered with 'yes/no', or a numeric value, you may simply state as much. If you incorporate code from the internet (which is not required and generally not advisable), please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "We will go through comparable code and concepts in the live learning sessions. If you run into trouble, start by using the help `help()` function in Python, to get information about the datasets and function in question. The internet is also a great resource when coding (though note that no outside searches are required by the assignment!). If you do incorporate code from the internet, please cite the source within your code (providing a URL is sufficient).\n",
    "\n",
    "Please bring questions that you cannot work out on your own to office hours, work periods or share with your peers on Slack. We will work with you through the issue.\n",
    "\n",
    "If you like, you may collaborate with others in the cohort. If you choose to do so, please indicate with whom you have worked with in your pull request by tagging their GitHub username. Separate submissions are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd43063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Import specific objects\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a59e07e-6abb-4f6c-9c1b-760b11626ce7",
   "metadata": {},
   "source": [
    "### Question 1: Classification using KNN\n",
    "\n",
    "We'll now use the `Caravan` dataset from the `ISLP` package. (You may use `Caravan.describe()` to review details of the dataset.) In this dataset, the response variable of interest is `Purchase`, which indicates if a given customer purchased a caravan insurance policy. We will simultaneously use all other variables in the dataset to predict the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6449268e-0e33-4976-83cf-5ada4b29597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  MGODOV  \\\n",
      "0          33         1        3         2         8       0       5       1   \n",
      "1          37         1        2         2         8       1       4       1   \n",
      "2          37         1        2         2         8       0       4       2   \n",
      "3           9         1        3         3         3       2       3       2   \n",
      "4          40         1        4         2        10       1       4       1   \n",
      "...       ...       ...      ...       ...       ...     ...     ...     ...   \n",
      "5817       36         1        1         2         8       0       6       1   \n",
      "5818       35         1        4         4         8       1       4       1   \n",
      "5819       33         1        3         4         8       0       6       0   \n",
      "5820       34         1        3         2         8       0       7       0   \n",
      "5821       33         1        3         3         8       0       6       1   \n",
      "\n",
      "      MGODGE  MRELGE  ...  APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  \\\n",
      "0          3       7  ...         0        0        0       1        0   \n",
      "1          4       6  ...         0        0        0       1        0   \n",
      "2          4       3  ...         0        0        0       1        0   \n",
      "3          4       5  ...         0        0        0       1        0   \n",
      "4          4       7  ...         0        0        0       1        0   \n",
      "...      ...     ...  ...       ...      ...      ...     ...      ...   \n",
      "5817       2       1  ...         0        0        0       1        0   \n",
      "5818       4       6  ...         0        0        0       1        0   \n",
      "5819       3       5  ...         0        0        0       1        0   \n",
      "5820       2       7  ...         0        0        0       0        0   \n",
      "5821       2       7  ...         0        0        0       0        0   \n",
      "\n",
      "      APLEZIER  AFIETS  AINBOED  ABYSTAND  Purchase  \n",
      "0            0       0        0         0        No  \n",
      "1            0       0        0         0        No  \n",
      "2            0       0        0         0        No  \n",
      "3            0       0        0         0        No  \n",
      "4            0       0        0         0        No  \n",
      "...        ...     ...      ...       ...       ...  \n",
      "5817         0       0        0         0        No  \n",
      "5818         0       0        0         0        No  \n",
      "5819         0       0        0         0       Yes  \n",
      "5820         0       0        0         0        No  \n",
      "5821         0       0        0         0        No  \n",
      "\n",
      "[5822 rows x 86 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>ALEVEN</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.253349</td>\n",
       "      <td>1.110615</td>\n",
       "      <td>2.678805</td>\n",
       "      <td>2.991240</td>\n",
       "      <td>5.773617</td>\n",
       "      <td>0.696496</td>\n",
       "      <td>4.626932</td>\n",
       "      <td>1.069907</td>\n",
       "      <td>3.258502</td>\n",
       "      <td>6.183442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076606</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.570079</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.031776</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.014256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.846706</td>\n",
       "      <td>0.405842</td>\n",
       "      <td>0.789835</td>\n",
       "      <td>0.814589</td>\n",
       "      <td>2.856760</td>\n",
       "      <td>1.003234</td>\n",
       "      <td>1.715843</td>\n",
       "      <td>1.017503</td>\n",
       "      <td>1.597647</td>\n",
       "      <td>1.909482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377569</td>\n",
       "      <td>0.072782</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.077403</td>\n",
       "      <td>0.562058</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.081632</td>\n",
       "      <td>0.210986</td>\n",
       "      <td>0.090463</td>\n",
       "      <td>0.119996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           MOSTYPE     MAANTHUI      MGEMOMV     MGEMLEEF     MOSHOOFD  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean     24.253349     1.110615     2.678805     2.991240     5.773617   \n",
       "std      12.846706     0.405842     0.789835     0.814589     2.856760   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%      10.000000     1.000000     2.000000     2.000000     3.000000   \n",
       "50%      30.000000     1.000000     3.000000     3.000000     7.000000   \n",
       "75%      35.000000     1.000000     3.000000     3.000000     8.000000   \n",
       "max      41.000000    10.000000     5.000000     6.000000    10.000000   \n",
       "\n",
       "            MGODRK       MGODPR       MGODOV       MGODGE       MRELGE  ...  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000  ...   \n",
       "mean      0.696496     4.626932     1.069907     3.258502     6.183442  ...   \n",
       "std       1.003234     1.715843     1.017503     1.597647     1.909482  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     4.000000     0.000000     2.000000     5.000000  ...   \n",
       "50%       0.000000     5.000000     1.000000     3.000000     6.000000  ...   \n",
       "75%       1.000000     6.000000     2.000000     4.000000     7.000000  ...   \n",
       "max       9.000000     9.000000     5.000000     9.000000     9.000000  ...   \n",
       "\n",
       "            ALEVEN     APERSONG      AGEZONG      AWAOREG       ABRAND  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.076606     0.005325     0.006527     0.004638     0.570079   \n",
       "std       0.377569     0.072782     0.080532     0.077403     0.562058   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       8.000000     1.000000     1.000000     2.000000     7.000000   \n",
       "\n",
       "           AZEILPL     APLEZIER       AFIETS      AINBOED     ABYSTAND  \n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000  \n",
       "mean      0.000515     0.006012     0.031776     0.007901     0.014256  \n",
       "std       0.022696     0.081632     0.210986     0.090463     0.119996  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     2.000000     3.000000     2.000000     2.000000  \n",
       "\n",
       "[8 rows x 85 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the \"Caravan\" dataset using the \"load_data\" function from the ISLP package\n",
    "Caravan = load_data('Caravan')\n",
    "\n",
    "# Add your code here\n",
    "print(Caravan)\n",
    "Caravan.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60779b-cba9-4972-aeeb-b89e65fda11c",
   "metadata": {},
   "source": [
    "Before fitting any model, it is essential to understand our data. Answer the following questions about the `Caravan` dataset (Hint: use `print` and `describe`):  \n",
    "_(i)_ How many observations (rows) does the dataset contain?\n",
    "- Number of observations (rows) : 5822\n",
    "\n",
    "_(ii)_ How many variables (columns) does the dataset contain?  \n",
    "- Number of variables (columns) : 86\n",
    "\n",
    "_(iii)_ What 'variable' type is the response variable `Purchase` (e.g., 'character', 'factor', 'numeric', etc)? What are the 'levels' of the variable?    \n",
    "- Variable type of Purchase : object\n",
    "- Levels of Purchase : ['No' 'Yes']\n",
    "\n",
    "_(iv)_ How many predictor variables do we have (Hint: all variables other than `Purchase`)?  \n",
    "- Number of predictor variables : 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a3a8ec5-98e4-431d-967b-ae1482127de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations (rows) : 5822\n",
      "Number of variables (columns) : 86\n",
      "Variable type of Purchase : object\n",
      "Levels of Purchase : ['No' 'Yes']\n",
      "Number of predictor variables : 85\n"
     ]
    }
   ],
   "source": [
    "# Add your code here\n",
    "data = Caravan\n",
    "target_variable = 'Purchase'\n",
    "print(f\"Number of observations (rows) : {data.shape[0]}\")\n",
    "print(f\"Number of variables (columns) : {data.shape[1]}\")\n",
    "print(f\"Variable type of {target_variable} : {data[target_variable].dtype}\")\n",
    "print(f\"Levels of {target_variable} : {data[target_variable].unique()}\")\n",
    "print(f\"Number of predictor variables : {data.shape[1]-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d31d9",
   "metadata": {},
   "source": [
    "Next, we must preform 'pre-processing' or 'data munging', to prepare our data for classification/prediction. For KNN, there are three essential steps. A first essential step is to 'standardize' the predictor variables. We can achieve this using the `scaler` method, provided as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c2901b1-82ce-4729-88d9-7d9985336221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MOSTYPE  MAANTHUI   MGEMOMV  MGEMLEEF  MOSHOOFD    MGODRK    MGODPR  \\\n",
      "0  0.680906  -0.27258  0.406697 -1.216964  0.779405 -0.694311  0.217444   \n",
      "1  0.992297  -0.27258 -0.859500 -1.216964  0.779405  0.302552 -0.365410   \n",
      "2  0.992297  -0.27258 -0.859500 -1.216964  0.779405 -0.694311 -0.365410   \n",
      "3 -1.187437  -0.27258  0.406697  0.010755 -0.970980  1.299414 -0.948264   \n",
      "4  1.225840  -0.27258  1.672893 -1.216964  1.479559  0.302552 -0.365410   \n",
      "\n",
      "     MGODOV    MGODGE    MRELGE  ...   ALEVEN  APERSONG   AGEZONG  AWAOREG  \\\n",
      "0 -0.068711 -0.161816  0.427670  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "1 -0.068711  0.464159 -0.096077  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "2  0.914172  0.464159 -1.667319  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "3  0.914172  0.464159 -0.619824  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "4 -0.068711  0.464159  0.427670  ... -0.20291 -0.073165 -0.081055 -0.05992   \n",
      "\n",
      "     ABRAND   AZEILPL  APLEZIER   AFIETS   AINBOED  ABYSTAND  \n",
      "0  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "1  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "2  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "3  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "4  0.764971 -0.022706  -0.07365 -0.15062 -0.087348 -0.118816  \n",
      "\n",
      "[5 rows x 85 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select predictors (excluding the 86th column)\n",
    "predictors = Caravan.iloc[:, :-1]\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "predictors_standardized = pd.DataFrame(scaler.fit_transform(predictors), columns=predictors.columns)\n",
    "\n",
    "# Display the head of the standardized predictors\n",
    "print(predictors_standardized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b3eaa-698e-4190-97cd-098e0e3d532e",
   "metadata": {},
   "source": [
    "_(v)_ Why is it important to standardize the predictor variables?  \n",
    "_(vi)_ Why did we elect not to standard our response variable `Purchase`?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40a8c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "# (v) Standaring the predictor variables is important for several reasons:\n",
    "#   1. Equal Weighting: It ensures that all predictor variables contribute equally to the model, preventing features with larger ranges from dominating.\n",
    "#   2. Algorithm Performance: Algorithms like k-nearest neighbors (KNN), support vector machines (SVM), and those that use gradient descent \n",
    "#      (like logistic regression) perform better and converge faster when features are on a similar scale.\n",
    "#   3. Distance Calculations: For algorithms that rely on distance metrics, like KNN, standardized features ensure meaningful and accurate distance calculations.\n",
    "\n",
    "# (vi) We do not standardize the response variable Purchase because:\n",
    "#   1. Categorical Nature: Purchase is a categorical variable with values 'Yes' and 'No'. Standardization is meant for numerical variables.\n",
    "#   2. Interpretability: Keeping Purchase in its original form ensures that the model's predictions (e.g., the probability of a purchase) are interpretable and meaningful.\n",
    "#   3. Algorithm Requirements: Classification algorithms are designed to handle categorical response variables and do not require them to be standardized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ffb22f",
   "metadata": {},
   "source": [
    "\n",
    "_(vii)_ A second essential step is to set a random seed. Do so below (Hint: use the `random.seed` function). Why is setting a seed important? Is the particular seed value important? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "230fd782-cfe1-45e6-ad00-a67e6b04d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Importance of Setting a Random Seed\n",
    "#   1. Reproducibility: Ensures experiments are reproducible by generating the same random numbers each run.\n",
    "#   2. Consistency: Maintains consistency across runs, crucial for splitting data, initializing weights, and random sampling.\n",
    "# 3. Comparison: Allows fair comparison between models by using the same subsets of data.\n",
    "\n",
    "# Importance of the Particular Seed Value\n",
    "#   1. Deterministic Output: Any seed value provides reproducible results. Different seeds give different but deterministic sequences.\n",
    "#   2. Arbitrary Choice: The specific value doesn't matter; using any integer as a seed achieves the goal.\n",
    "#   3. random.seed(42) is often used as a convention in examples and tutorials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4862c6-ed52-402f-b3f0-fead91646033",
   "metadata": {},
   "source": [
    "_(viii)_ A third essential step is to split our standardized data into separate training and testing sets. We will split into 75% training and 25% testing. The provided code randomly partitions our data, and creates linked training sets for the predictors and response variables. Extend the code to create a non-overlapping test set for the predictors and response variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbe9f219-571b-476b-9f5b-b47431c803b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing sets are non-overlapping.\n"
     ]
    }
   ],
   "source": [
    "# Create a random vector of True and False values\n",
    "split = np.random.choice([True, False], size=len(predictors_standardized), replace=True, p=[0.75, 0.25])\n",
    "\n",
    "# Define the training set for X (predictors)\n",
    "training_X = predictors_standardized[split]\n",
    "\n",
    "# Define the training set for Y (response)\n",
    "training_Y = Caravan.loc[split, 'Purchase']\n",
    "\n",
    "# Define the testing set for X (predictors)\n",
    "testing_X = predictors_standardized[~split]\n",
    "\n",
    "# Define the testing set for Y (response)\n",
    "testing_Y = Caravan.loc[~split, 'Purchase']\n",
    "\n",
    "# Extract the indices for training and testing\n",
    "training_indices = training_X.index\n",
    "testing_indices = testing_X.index\n",
    "\n",
    "# Check for overlapping indices\n",
    "overlapping_indices = set(training_indices).intersection(testing_indices)\n",
    "\n",
    "if overlapping_indices:\n",
    "    print(\"Training and testing sets are overlapping.\")\n",
    "else:\n",
    "    print(\"Training and testing sets are non-overlapping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f16dbc-0be6-4cc8-b2c4-edab7042c702",
   "metadata": {},
   "source": [
    "_(ix)_ We are finally set to fit the KNN model. In Python, we can use the `KNeighborsClassifier()` function. Fit the KNN with k=1. (You may review arguments to knn by typing `help(knn.fit)`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e6a117de-279b-4320-b64e-4051ba2887d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fit the KNN model, k=1.\n"
     ]
    }
   ],
   "source": [
    "# Add your code here\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create a KNN classifier with k=1\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn1.fit(training_X, training_Y)\n",
    "print(\"Successfully fit the KNN model, k=1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33a32a-95d3-49db-bb1b-663360267b18",
   "metadata": {},
   "source": [
    "Using your fit model, answer the following questions:   \n",
    "_(x)_ What is the prediction accuracy? (Hint: use the `score` method, and compare your model to `testing_Y`)  \n",
    "- Prediction Accuracy: 0.8902677988242979\n",
    "\n",
    "_(xi)_ What is the predictor error ? (Hint: compute it from the accuracy)\n",
    "- Predictor Error : 0.10973220117570215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74dbe6c4-1a4d-4f06-9e2e-597da03952ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.8902677988242979\n"
     ]
    }
   ],
   "source": [
    "# prediction accuracy rate\n",
    "accuracy = knn1.score(testing_X, testing_Y)\n",
    "print(f\"Prediction Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9384d3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor Error : 0.10973220117570215\n"
     ]
    }
   ],
   "source": [
    "# prediction error rate\n",
    "error = 1- accuracy\n",
    "print(f\"Predictor Error : {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9342c-9dcd-4f6d-b437-6065417483db",
   "metadata": {},
   "source": [
    "_(xii)_ How does this prediction error/accuracy compare to what could be achieved via random guesses? To answer this, consider the percent of customers in the `Caravan` dataset who actually purchase insurance, computed below:\n",
    "- The random accuracy consistently falls within the range of 87-89%, and the model accuracy is also 89%. It suggests that the model's performance is comparable to random guessing.\n",
    "- Given that the model accuracy is similar to the range of random accuracy, it implies that the model may not be effectively capturing the underlying patterns in the data. While the model's accuracy is relatively high, its performance is not significantly better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c89ade30-3465-4104-b300-61d78b319d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.357325538911216\n",
      "Percentage_purchase from testing_Y :  6.615598885793872\n",
      "Mean Random Guess Accuracy (1000 iterations): 88.21456564337035\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of customers who purchase insurance\n",
    "percentage_purchase = (Caravan['Purchase'].eq('Yes').sum() / len(Caravan['Purchase'])) * 100\n",
    "\n",
    "print(percentage_purchase)\n",
    "\n",
    "# 1 To compare based on the same dataset, calculating the percentage_purchase in testing_Y\n",
    "percentage_purchase_testY = (testing_Y.eq('Yes').sum() / testing_Y.eq('No').sum()) * 100\n",
    "print(f\"Percentage_purchase from testing_Y :  {percentage_purchase_testY}\")\n",
    "\n",
    "# 2 Random guesses based on the result from step 1\n",
    "# Determine the majority class label - 'no' in this case\n",
    "majority_class_label = 'Yes' if percentage_purchase > 0.5 else 'No'\n",
    "\n",
    "# 3 Repeat random guessing and accuracy calculation for 1000 iterations\n",
    "num_iterations = 1000\n",
    "mean_random_guess_accuracy_list = []\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    # 3.1 Generate random guesses for the length of testing_Y based on the data distribution\n",
    "    random_guesses = np.random.choice(['Yes', 'No'], size=len(testing_Y), p=[percentage_purchase/100, 1 - percentage_purchase/100])\n",
    "    \n",
    "    # 3.2 Count the number of correct guesses\n",
    "    num_correct_guesses = np.sum(random_guesses == testing_Y)\n",
    "    \n",
    "    # 3.3 Calculate the accuracy of random guessing for this iteration\n",
    "    random_guess_accuracy = (num_correct_guesses / len(testing_Y)) * 100\n",
    "    \n",
    "    #3.4 Append the accuracy to the list\n",
    "    mean_random_guess_accuracy_list.append(random_guess_accuracy)\n",
    "\n",
    "# Compute the mean accuracy from the list of accuracies\n",
    "mean_random_guess_accuracy = np.mean(mean_random_guess_accuracy_list)\n",
    "\n",
    "print(\"Mean Random Guess Accuracy (1000 iterations):\", mean_random_guess_accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e19b5e-ad65-47f8-a3ef-e0f68a75048e",
   "metadata": {},
   "source": [
    "_(xiii)_ Fit a second KNN model, with $K=3$. Does this model perform better (i.e., have higher accuracy, compared to a random guess)?\n",
    "- Since the model accuracy of 92.95% is significantly higher than the random guess accuracy range, it indicates that the model performs much better than random guessing. This suggests that the model effectively captures patterns in the data and makes more accurate predictions compared to simply guessing based on the distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fedbe4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fit the KNN model, k=3.\n",
      "Prediction Accuracy: 0.9294578706727629\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Create a KNN classifier with k=1\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn3.fit(training_X, training_Y)\n",
    "print(\"Successfully fit the KNN model, k=3.\")\n",
    "\n",
    "accuracy = knn3.score(testing_X, testing_Y)\n",
    "print(f\"Prediction Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c5050f",
   "metadata": {},
   "source": [
    "# Criteria\n",
    "\n",
    "|Criteria            |Complete           |Incomplete          |\n",
    "|--------------------|---------------|--------------|\n",
    "|Classification using KNN|All steps are done correctly and the answers are correct.|At least one step is done incorrectly leading to a wrong answer.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf69b4d",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "🚨 **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** 🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-2`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_2.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/applying_statistical_concepts/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "497a84dc8fec8cf8d24e7e87b6d954c9a18a327edc66feb9b9ea7e9e72cc5c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
